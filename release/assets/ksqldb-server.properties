

confluent.support.metrics.enable=false
#------ Endpoint config -------
# The URL the KSQL server will listen on:
listeners=http://0.0.0.0:8088

# advertised.listener=?


#------ Logging config -------
# headless模式下不能自动创建, 需要手动创建
# Automatically create the processing log topic if it does not already exist:
ksql.logging.processing.topic.auto.create=true

# Automatically create a stream within KSQL for the processing log:
ksql.logging.processing.stream.auto.create=true

# 发生错误时，将错误行记录到processing log:
ksql.logging.processing.rows.include=true

#------ External service config -------

# The set of Kafka brokers to bootstrap Kafka cluster information from:
bootstrap.servers=${bootstrapServers}

ksql.schema.registry.url=${schemaRegistryServer}

# Set the batch expiry to Integer.MAX_VALUE to ensure that queries will not
# terminate if the underlying Kafka cluster is unavailable for a period of
# time.
ksql.streams.producer.delivery.timeout.ms=2147483647

# Set the maximum allowable time for the producer to block to
# Long.MAX_VALUE. This allows KSQL to pause processing if the underlying
# Kafka cluster is unavailable.
ksql.streams.producer.max.block.ms=9223372036854775807

# For better fault tolerance and durability, set the replication factor and minimum insync replicas
# for the KSQL Server's internal topics.
# Note: the value 3 requires at least 3 brokers in your Kafka cluster.
ksql.internal.topic.replicas=3
ksql.internal.topic.min.insync.replicas=2

# Configure underlying Kafka Streams internal topics in order to achieve better fault tolerance and
# durability, even in the face of Kafka broker failures. Highly recommended for mission critical applications.
# Note that value 3 requires at least 3 brokers in your kafka cluster
# See https://docs.confluent.io/current/streams/developer-guide/config-streams.html#recommended-configuration-parameters-for-resiliency
ksql.streams.replication.factor=3
ksql.streams.producer.acks=all
ksql.streams.topic.min.insync.replicas=2


#定义ksqldb集群的ID,区分不同的个集群
ksql.service.id=${ksqlServiceId}
ksql.streams.auto.offset.reset=earliest

# 工作线程的数量
ksql.streams.num.stream.threads=${ksqlThreadSize}

# default: at_least_once, 也可以设置成exactly_once
ksql.streams.processing.guarantee=at_least_once

# 自动创建的topic的前缀
ksql.output.topic.name.prefix=${ksqlOutputTopicPrefix}

#如果碰到反序列化失败，要如何处理， 此处设置为true,表示整个instance将退出，反之只会记录在log里
ksql.fail.on.deserialization.error=true

#publish message失败时，退出：
ksql.fail.on.production.error=true

# 有状态的操作，如Aggregate&join等操作的数据暂存区
ksql.streams.state.dir=/tmp/kafka-streams

# 启用心跳检查：
ksql.heartbeat.enable = true

# Bump the number of replicas for state storage for stateful operations
# like aggregations and joins. By having two replicas (one active and one
# standby) recovery from node failures is quicker since the state doesn't
# have to be rebuilt from scratch. This configuration is also essential for
# pull queries to be highly available during node failures
ksql.streams.num.standby.replicas=2

# 集群节点挂掉时，是否将pull query转发到standby节点, 会有数据一致性问题，但是可以提高可用性。
# 需要确保ksql.streams.num.standby.replicas >1
ksql.query.pull.enable.standby.reads=true

# Headless模式下要读取的KSQL文件:

#if(${ksqlHeadlessMode})
ksql.queries.file=/etc/ksqldb/scripts/topology.ksql
#else
# 当前模式为interactive模式，可以使用ksql-cli来管理ksqldb
#end

# Interactive模式下persistent query的并发数量：
ksql.query.persistent.active.limit=${interactiveQueryLimit}